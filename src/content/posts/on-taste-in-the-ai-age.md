---
title: "On Taste in the AI Age"
pubDate: 2025-03-16
author: "Adam Bossy-Mendoza"
showToc: false
emoji: "ðŸŽ¨"
description: "A contrarian take on the popular meme about taste being the key differentiator in the AI age, and why getting AI to work reliably is what really matters."
---

<div class="flex justify-center my-0">
  <a href="https://x.com/being_on_line/status/1764680655630164085">
    <img src="https://res.cloudinary.com/dwt45tvzy/image/upload/v1742152479/Screenshot_2025-03-16_at_3.05.48_PM_q6ilt7.png" alt="An example of the taste meme" class="mx-auto" style="margin-top: 0 !important; margin-bottom: 0 !important" />
  </a>
</div>

### Contrarian take: the meme about taste being the differentiator in the AI age is wrong.

The meme assumes that being technical was *really important* until the AI wave started, but that hasn't been true for a long time. The technical part of SaaS was already commodifiedâ€”it just used to be more expensive and took longer than it does now. Jobs made this clear in his Second Act at Apple, and companies like Tesla, Airbnb, and Peloton leaned into design as a competitive advantage *long before* AI was in the picture.

<div class="flex justify-center">
  <a href="https://x.com/dhh/status/1901254339546509696">
    <img src="https://res.cloudinary.com/dwt45tvzy/image/upload/v1742153793/Screenshot_2025-03-16_at_3.36.04_PM_dp7orn.png" alt="What's old is new" class="mx-auto" style="margin-top: .85em !important" />
  </a>
</div>

AI will win if it *just works* *more reliably* than its competition, across every nook and cranny that the software world can find, ranging from boring headless SaaS agents to sparkly media tooling used to create the next generation of art to robots doing useful stuff. 

I think better taste will naturally emerge as a consequence of AI, but it's not what we should be indexing on to build more competitive products and companies. The baseline for acceptable taste will simply become higher.

### How AI will impact design and UI

The argument that "taste" will be the main differentiator assumes that AI will be used to primarily produce software that looks like the current generation of SaaS. But software is destined to look and feel *dramatically* different.

First, LLMs strip away a ton of UI right off the bat. ChatGPT, for example, is just text in and text out, but within that minimal interface, it enables a broader range of functionality than anything in history. We're seeing OpenAI and other AI companies stack more features and UI chrome onto this basic model, but that coreâ€”text in, text outâ€”is what drives the value. And because of that, a huge amount of UI will just *disappear*. Like, why should settings screens continue to exist?

Many interfaces will collapse or be absorbed into natural language interactions. That doesn't mean *everything* should work this way, otherwise we'd end up with mystery meat navigation and no discoverability, but let's be realâ€”information architecture in complex software is *hard* for both users and developers. Natural language interfaces solve a whole category of design problems in one fell swoop.

On top of that, a huge chunk of future software will be AI agents that virtually won't even *have* an interface. They'll just operate in the background or interact through existing mediums. So if agents are the future, what makes one better than another? Not its aesthetics, but whether it actually *works* better and does *more* than the competition.

### AI buckles at a certain level of complexity

To be clear, vibe coding lets you *start* an idea and *test* the market with little to no coding skill. But software quickly grows complex. Even a modicum of success adds layers of complexity, and at a certain point, AI buckles under the weight of it. That's why, once your AI-built app finds PMF, your tech company is going to start looking like every other oneâ€”because you'll need engineers to step in and actually make it work at scale.

<div class="flex justify-center">
  <a href="https://x.com/t_blom/status/1898903125735703025">
    <img src="https://res.cloudinary.com/dwt45tvzy/image/upload/v1742218896/Screenshot_2025-03-17_at_9.41.04_AM_vh4oez.png" alt="Tom fleeing to Windsurf" class="mx-auto" style="margin-top: .85em !important" />
  </a>
</div>

AI is advancing quickly, but there's still a long road ahead. LLMs are highly non-deterministic and there are *so* many things AI simply *can't* do, and those gaps set a new and distant frontier for the tech world. You'll need skilled engineers to act as AI babysitters, understanding what's happening when a complex AI-coded app inevitably breaks <a href="#footnote-0" id="footnote-ref-0">[0]</a>. Because, at the end of the day, what matters isn't tasteâ€”it's getting the damn thing to *work reliably*.

AI also can't create anything *new*. Sure, it speeds up the menial parts of the process, but creative breakthroughs still require the slow, tedious work: talking to a shit ton of customers, trying a shit ton of things that fail, having a random epiphany in the shower just as you're about to throw in the towel. Yes, AI compresses timelines significantly, but it doesn't make them collapse into nothingness.

### AI tools just need to *work* to be great

I contend that a vast majority of AI tools that win will be the ones that *work the best*.

Yes, ChatGPT is designed with good "taste"â€”it feels natural to interact with. But after one too many hallucinations, people flee for the next chatbot. No one will care if an AI's personality is bland or boring or woke or anti-woke as long as it *actually gets the job done better*.

Anything AI commodifies *stops* being a competitive advantage. The real differentiation will come from what AI *can't* doâ€”and this is where the taste argument comes from. Sure, Bolt and Lovable look slick, but at some point, they'll fail to meet users' goals. Their users apps will become too complex, some abstraction will break, and users will jump ship. The companies that *win* will be the ones that continuously improve *how well* their AI tools workâ€”not the ones that focus on how the look and feel. This is a probably of prioritization and engineering, not taste. 

It's important not to overlook that AI is non-deterministic, and therefore doesn't work *as reliably* as traditional software. And anybody that's ever used software before knows how frustrating it is when it doesn't work. Yes, it's amazing that you can vibe code a flight simulator or auto-generate market analysis without hiring an intern, but the cost of your AI-generated flight simulator crashing because of a bug *buried deep* in the AI's code, or your AI analysis leading you to make an investment mistake that loses you $MMs, is a huge liability.

And right now? *Nobody* has gotten AI to work *that* reliably yet.

<p id="footnote-0">[0] And by the way, if AI is leading us to hire fewer, more productive engineers, each engineers' scope will automatically grow dramatically. We'll need to know more stuff to keep the engine moving.</p>

[1] Since it's important to see other perspectives, you should read [a post](https://www.workingtheorys.com/p/taste-is-eating-silicon-valley) by one of my favorite writers online, Anu Atluru. She makes a cogent argument *in favor* of taste as a differentiator.